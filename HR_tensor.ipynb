{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HR - Hvilke ansatte kommer til å slutte? - Tensorflow\n",
    "\n",
    "Datasettet er tatt fra https://www.kaggle.com/ludobenistant/hr-analytics\n",
    "\n",
    "\n",
    "## Intro\n",
    "Vi ønsker å lage en modell som med god treffsikkert greier å forutse hvilke ansatte som kommer til å forlate selskapet i nærmeste fremtid.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Les inn datasettet i en Pandas DataFrame\n",
    "hr_data = pd.read_csv('data/HR_comma_sep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffel datasettet så det ikke ligger sortert.\n",
    "hr_data = hr_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RandD</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.81</td>\n",
       "      <td>4</td>\n",
       "      <td>227</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>marketing</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.54</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.94</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>4</td>\n",
       "      <td>221</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RandD</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.68</td>\n",
       "      <td>4</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>product_mng</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.57             0.90               3                   256   \n",
       "1                0.21             0.81               4                   227   \n",
       "2                0.63             0.50               4                   172   \n",
       "3                0.45             0.54               2                   138   \n",
       "4                0.64             0.94               3                   150   \n",
       "5                0.71             0.71               4                   221   \n",
       "6                0.39             0.56               2                   156   \n",
       "7                0.69             0.98               4                   180   \n",
       "8                0.44             0.61               3                   147   \n",
       "9                0.92             0.68               4                   178   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  \\\n",
       "0                   4              0     0                      0   \n",
       "1                   5              0     0                      0   \n",
       "2                   2              0     0                      0   \n",
       "3                   3              0     1                      0   \n",
       "4                   2              0     0                      0   \n",
       "5                   3              0     0                      0   \n",
       "6                   3              0     1                      0   \n",
       "7                   3              0     0                      0   \n",
       "8                   4              0     0                      0   \n",
       "9                   3              0     0                      0   \n",
       "\n",
       "         sales  salary  \n",
       "0        RandD     low  \n",
       "1    marketing  medium  \n",
       "2    technical     low  \n",
       "3    technical  medium  \n",
       "4    technical  medium  \n",
       "5    technical     low  \n",
       "6           IT     low  \n",
       "7      support  medium  \n",
       "8        RandD     low  \n",
       "9  product_mng     low  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 10)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 14999 rader (observasjoner) , 10 kolonner (features)\n",
    "hr_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.612834</td>\n",
       "      <td>0.716102</td>\n",
       "      <td>3.803054</td>\n",
       "      <td>201.050337</td>\n",
       "      <td>3.498233</td>\n",
       "      <td>0.144610</td>\n",
       "      <td>0.238083</td>\n",
       "      <td>0.021268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248631</td>\n",
       "      <td>0.171169</td>\n",
       "      <td>1.232592</td>\n",
       "      <td>49.943099</td>\n",
       "      <td>1.460136</td>\n",
       "      <td>0.351719</td>\n",
       "      <td>0.425924</td>\n",
       "      <td>0.144281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "count        14999.000000     14999.000000    14999.000000   \n",
       "mean             0.612834         0.716102        3.803054   \n",
       "std              0.248631         0.171169        1.232592   \n",
       "min              0.090000         0.360000        2.000000   \n",
       "25%              0.440000         0.560000        3.000000   \n",
       "50%              0.640000         0.720000        4.000000   \n",
       "75%              0.820000         0.870000        5.000000   \n",
       "max              1.000000         1.000000        7.000000   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident          left  \\\n",
       "count          14999.000000        14999.000000   14999.000000  14999.000000   \n",
       "mean             201.050337            3.498233       0.144610      0.238083   \n",
       "std               49.943099            1.460136       0.351719      0.425924   \n",
       "min               96.000000            2.000000       0.000000      0.000000   \n",
       "25%              156.000000            3.000000       0.000000      0.000000   \n",
       "50%              200.000000            3.000000       0.000000      0.000000   \n",
       "75%              245.000000            4.000000       0.000000      0.000000   \n",
       "max              310.000000           10.000000       1.000000      1.000000   \n",
       "\n",
       "       promotion_last_5years  \n",
       "count           14999.000000  \n",
       "mean                0.021268  \n",
       "std                 0.144281  \n",
       "min                 0.000000  \n",
       "25%                 0.000000  \n",
       "50%                 0.000000  \n",
       "75%                 0.000000  \n",
       "max                 1.000000  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      "satisfaction_level       14999 non-null float64\n",
      "last_evaluation          14999 non-null float64\n",
      "number_project           14999 non-null int64\n",
      "average_montly_hours     14999 non-null int64\n",
      "time_spend_company       14999 non-null int64\n",
      "Work_accident            14999 non-null int64\n",
      "left                     14999 non-null int64\n",
      "promotion_last_5years    14999 non-null int64\n",
      "sales                    14999 non-null object\n",
      "salary                   14999 non-null object\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "hr_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endre input data\n",
    "Mange maskinlæringsalgoritmer er svake på å jobbe med String. Nevrale Nettverk er blant dem så vi må mappe om stringene. Vi mapper om alle strings til nummere som referer til hver sin string for en feature. F.eks så blir 'low' i 'salary' featuren til 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['RandD', 'marketing', 'technical', 'IT', 'support', 'product_mng',\n",
       "        'sales', 'accounting', 'management', 'hr'], dtype=object),\n",
       " array(['low', 'medium', 'high'], dtype=object))"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_data['sales'].unique(),hr_data['salary'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modellen vi skal bruke kan ikke håndtere String verdier så vi gjør dem om til numersike verdier. \n",
    "# Gjør om featuren (kolonnen) \"sales\" og featuren \"salary\".\n",
    "\n",
    "hr_data['sales'].replace(['sales', 'accounting', 'hr', 'technical', 'support', 'management',\n",
    "        'IT', 'product_mng', 'marketing', 'RandD'], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], inplace = True)\n",
    "\n",
    "hr_data['salary'].replace(['low', 'medium', 'high'], [0, 1, 2], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Korrelasjon\n",
    "Før vi begynner å lage en modell kan det være interessant å se litt nærmere på datasettet. Her har jeg laget en liten korrelasjonsmatrise slik at vi kan se på de linære forholdene mellom de forskjellige featurene i datasettet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>satisfaction_level</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105021</td>\n",
       "      <td>-0.142970</td>\n",
       "      <td>-0.020048</td>\n",
       "      <td>-0.100866</td>\n",
       "      <td>0.058697</td>\n",
       "      <td>-0.388375</td>\n",
       "      <td>0.025605</td>\n",
       "      <td>0.015413</td>\n",
       "      <td>0.050022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_evaluation</th>\n",
       "      <td>0.105021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.349333</td>\n",
       "      <td>0.339742</td>\n",
       "      <td>0.131591</td>\n",
       "      <td>-0.007104</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>-0.008684</td>\n",
       "      <td>0.011855</td>\n",
       "      <td>-0.013002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_project</th>\n",
       "      <td>-0.142970</td>\n",
       "      <td>0.349333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417211</td>\n",
       "      <td>0.196786</td>\n",
       "      <td>-0.004741</td>\n",
       "      <td>0.023787</td>\n",
       "      <td>-0.006064</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>-0.001803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_montly_hours</th>\n",
       "      <td>-0.020048</td>\n",
       "      <td>0.339742</td>\n",
       "      <td>0.417211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127755</td>\n",
       "      <td>-0.010143</td>\n",
       "      <td>0.071287</td>\n",
       "      <td>-0.003544</td>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_spend_company</th>\n",
       "      <td>-0.100866</td>\n",
       "      <td>0.131591</td>\n",
       "      <td>0.196786</td>\n",
       "      <td>0.127755</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.144822</td>\n",
       "      <td>0.067433</td>\n",
       "      <td>-0.001611</td>\n",
       "      <td>0.048715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work_accident</th>\n",
       "      <td>0.058697</td>\n",
       "      <td>-0.007104</td>\n",
       "      <td>-0.004741</td>\n",
       "      <td>-0.010143</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.154622</td>\n",
       "      <td>0.039245</td>\n",
       "      <td>0.019215</td>\n",
       "      <td>0.009247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>-0.388375</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>0.023787</td>\n",
       "      <td>0.071287</td>\n",
       "      <td>0.144822</td>\n",
       "      <td>-0.154622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.061788</td>\n",
       "      <td>-0.043814</td>\n",
       "      <td>-0.157898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <td>0.025605</td>\n",
       "      <td>-0.008684</td>\n",
       "      <td>-0.006064</td>\n",
       "      <td>-0.003544</td>\n",
       "      <td>0.067433</td>\n",
       "      <td>0.039245</td>\n",
       "      <td>-0.061788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015170</td>\n",
       "      <td>0.098119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>0.015413</td>\n",
       "      <td>0.011855</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.001611</td>\n",
       "      <td>0.019215</td>\n",
       "      <td>-0.043814</td>\n",
       "      <td>0.015170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>0.050022</td>\n",
       "      <td>-0.013002</td>\n",
       "      <td>-0.001803</td>\n",
       "      <td>-0.002242</td>\n",
       "      <td>0.048715</td>\n",
       "      <td>0.009247</td>\n",
       "      <td>-0.157898</td>\n",
       "      <td>0.098119</td>\n",
       "      <td>0.033415</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       satisfaction_level  last_evaluation  number_project  \\\n",
       "satisfaction_level               1.000000         0.105021       -0.142970   \n",
       "last_evaluation                  0.105021         1.000000        0.349333   \n",
       "number_project                  -0.142970         0.349333        1.000000   \n",
       "average_montly_hours            -0.020048         0.339742        0.417211   \n",
       "time_spend_company              -0.100866         0.131591        0.196786   \n",
       "Work_accident                    0.058697        -0.007104       -0.004741   \n",
       "left                            -0.388375         0.006567        0.023787   \n",
       "promotion_last_5years            0.025605        -0.008684       -0.006064   \n",
       "sales                            0.015413         0.011855        0.005577   \n",
       "salary                           0.050022        -0.013002       -0.001803   \n",
       "\n",
       "                       average_montly_hours  time_spend_company  \\\n",
       "satisfaction_level                -0.020048           -0.100866   \n",
       "last_evaluation                    0.339742            0.131591   \n",
       "number_project                     0.417211            0.196786   \n",
       "average_montly_hours               1.000000            0.127755   \n",
       "time_spend_company                 0.127755            1.000000   \n",
       "Work_accident                     -0.010143            0.002120   \n",
       "left                               0.071287            0.144822   \n",
       "promotion_last_5years             -0.003544            0.067433   \n",
       "sales                             -0.002387           -0.001611   \n",
       "salary                            -0.002242            0.048715   \n",
       "\n",
       "                       Work_accident      left  promotion_last_5years  \\\n",
       "satisfaction_level          0.058697 -0.388375               0.025605   \n",
       "last_evaluation            -0.007104  0.006567              -0.008684   \n",
       "number_project             -0.004741  0.023787              -0.006064   \n",
       "average_montly_hours       -0.010143  0.071287              -0.003544   \n",
       "time_spend_company          0.002120  0.144822               0.067433   \n",
       "Work_accident               1.000000 -0.154622               0.039245   \n",
       "left                       -0.154622  1.000000              -0.061788   \n",
       "promotion_last_5years       0.039245 -0.061788               1.000000   \n",
       "sales                       0.019215 -0.043814               0.015170   \n",
       "salary                      0.009247 -0.157898               0.098119   \n",
       "\n",
       "                          sales    salary  \n",
       "satisfaction_level     0.015413  0.050022  \n",
       "last_evaluation        0.011855 -0.013002  \n",
       "number_project         0.005577 -0.001803  \n",
       "average_montly_hours  -0.002387 -0.002242  \n",
       "time_spend_company    -0.001611  0.048715  \n",
       "Work_accident          0.019215  0.009247  \n",
       "left                  -0.043814 -0.157898  \n",
       "promotion_last_5years  0.015170  0.098119  \n",
       "sales                  1.000000  0.033415  \n",
       "salary                 0.033415  1.000000  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAFjCAYAAABCLW4YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nny3IewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123dcee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Korrelasjon Matrise\n",
    "corr = hr_data.corr()\n",
    "corr = (corr)\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)\n",
    "sns.plt.title('Heatmap of Correlation Matrix')\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>time_spend_company</th>\n",
       "      <td>0.144822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_montly_hours</th>\n",
       "      <td>0.071287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_project</th>\n",
       "      <td>0.023787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_evaluation</th>\n",
       "      <td>0.006567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>-0.043814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <td>-0.061788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work_accident</th>\n",
       "      <td>-0.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>-0.157898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satisfaction_level</th>\n",
       "      <td>-0.388375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           left\n",
       "time_spend_company     0.144822\n",
       "average_montly_hours   0.071287\n",
       "number_project         0.023787\n",
       "last_evaluation        0.006567\n",
       "sales                 -0.043814\n",
       "promotion_last_5years -0.061788\n",
       "Work_accident         -0.154622\n",
       "salary                -0.157898\n",
       "satisfaction_level    -0.388375"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ser her kun på \"label som er left\" fordi det er den verdien vi ønsker å se features effekt på.\n",
    "# Korelasjonmatrisen viser kun linære forhold mellom \"left\" og de andre avhengige variablene.\n",
    "corr_left = pd.DataFrame(corr['left'].drop('left'))\n",
    "corr_left.sort_values(by = 'left', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over kan vi se det linære forholdet mellom våre features og \"left\". Ikke overraskende så korrelerer \"satisfaction_level\" negativt med \"left\"\n",
    "\n",
    "\n",
    "\n",
    "# Tensorflow Neural Network Model\n",
    "\n",
    "## Splitting av dataset\n",
    "\n",
    "For å bygge en maksinkæringsmodell ønsker man å dele opp datasett inn i et treningsett og testsett. Treningsettet brukes til å trene opp modellen, mens testsett brukes for å teste treffsikkerheten til modellen. Her har jeg valgt å dele inn datasette 80% trening og 20% test.\n",
    "\n",
    "I mange maskinslæringsmodeller er det også vanlig å ha med et validersinsett. Dette sette brukes til å sette/tune hyperparametere (f.eks læringsrate).\n",
    "For simpelhetens skyld dropper vi å ta med valideringsett her da det ikke spiller noen viktige rolle i denne tutorialen. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train-Test split. Splitter \n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Siden vi ønsker å finne ut av hvilke ansatt sannsynligvis snart slutter(left), så må vi \"ta ut\" \"left\" kolonnen fra datasette. Dette blir da den avhengige variabelen i modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = hr_data.pop('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train, data_test, label_train, label_test = train_test_split(hr_data, label, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9838</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7689</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4</td>\n",
       "      <td>252</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6557</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6872</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.69</td>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      satisfaction_level  last_evaluation  number_project  \\\n",
       "9838                0.41             0.45               2   \n",
       "7689                0.63             0.91               4   \n",
       "6557                0.65             0.95               3   \n",
       "6872                0.67             0.83               3   \n",
       "820                 0.86             0.69               5   \n",
       "\n",
       "      average_montly_hours  time_spend_company  Work_accident  \\\n",
       "9838                   150                   3              0   \n",
       "7689                   252                   3              1   \n",
       "6557                   266                   3              1   \n",
       "6872                   220                   3              0   \n",
       "820                    157                   4              0   \n",
       "\n",
       "      promotion_last_5years  sales  salary  \n",
       "9838                      0      4       1  \n",
       "7689                      0      4       1  \n",
       "6557                      0      4       0  \n",
       "6872                      0      0       0  \n",
       "820                       0      4       0  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Titter bare på de første elementene i det \"nye\" datasettet uten \"left\" kolonnen\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gjør om Pandas DataFrame til python arrays da de er letter å jobbe med. \n",
    "x_train = data_train.values\n",
    "x_test = data_test.values\n",
    "y_train = label_train.values\n",
    "y_test_cls  = label_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X-train:  (11999, 9)\n",
      "Shape Y-train:  (11999,)\n",
      "Shape X-test:  (3000, 9)\n",
      "Shape Y-test:  (3000,)\n",
      "Shaper new label train: (11999, 1)\n",
      "Shaper new label test: (3000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 8999 rader med inputs. 9 kolonner med features\n",
    "print (\"Shape X-train: \", data_train.shape)\n",
    "print (\"Shape Y-train: \", label_train.shape)\n",
    "print (\"Shape X-test: \", data_test.shape)\n",
    "print (\"Shape Y-test: \", label_test.shape)\n",
    "\n",
    "label_train = pd.DataFrame(label_train.values.reshape((11999,1)))\n",
    "label_test = pd.DataFrame(label_test.values.reshape((3000,1)))\n",
    "print (\"Shaper new label train: {}\".format(label_train.shape))\n",
    "print (\"Shaper new label test: {}\".format(label_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders\n",
    "\n",
    "Som nevnt tidligere er placeholeder containere/arrays som ikke inneholder noen verdi før en Tensorflow Session blir kjørt og man fyllter opp placeholderene med verdier. Placeholderen kan få inn forksjellige inputs(data) ved hver kjøring og det skjer ingen tuning eller optimering av disse. \n",
    "\n",
    "Før vi definerer placeholdere må vi bestemme oss for hvor mange \"layers\" det skal være i nettverkt, og hvor mange hidden units som skal være i hvert layer. Her har jeg valgt å gjøre det enklest mulig. Det er kun 1 hidden layer, og i dette layer så ligger det 9 noder, som er like mange noder som det er i input layer.\n",
    "\n",
    "I input layer er det alltid like mange noder som er features i modellen, så vi stter antall kolonner i placeholder til antall features. Antall rader setter vi til \"None\" noe som betyr at man kan fylle opp placeholderen med et vilkårlig antall ansatt-data.\n",
    "\n",
    "Input data er i dette tilfelle data for 1 ansatt/person.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# La oss velge layers. 9 input_units, en for hver feature. 9 hidden er valgt random, for simplicity.\n",
    "# La oss lage en konstant som holder antall features.\n",
    "ANTALL_FEATURES = 9\n",
    "input_units = 9\n",
    "HIDDEN_UNITS = 9\n",
    "OUTPUT_UNITS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Siden X(inputs) ikke skal forandres/tunes så lager vi en Placeholder for disse verdiene\n",
    "# Placeholders er for verdier som skal/kan endres for hver kjøring av grafen.\n",
    "# Placeholders blir det ikke regner Gradien (partiel deriverte) for \n",
    "\n",
    "# Bruke \"None\" som man kan ha et ukjent antall observasjon/rader inn til X\n",
    "x_placeh = tf.placeholder(tf.float32, shape=[None, ANTALL_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "y_placeh = tf.placeholder(tf.float32, shape=[None,OUTPUT_UNITS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true_cls_placeh = tf.placeholder(tf.int64, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Konvertere heltall verdi til forskjellige klassifiseringer. 1 blir [1,0] og 0 blir [0, 1] \n",
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    \n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hot_train = dense_to_one_hot(y_train, 2)\n",
    "y_hot_test = dense_to_one_hot(y_test_cls, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights og Biases\n",
    "Setter default weights/koefisientene for datasettet. Random verdi mellom -1 og 1. Alle verdier like sannsynlig.\n",
    "\n",
    "Vektene er hva som ligger på edges(kantene) fra en node i et lag, si (n-layer), til alle noden i lag (n-layer+1)\n",
    "Siden vi har 9 features, har vi 9 input noder. Siden hver input node har 9 kanter, så får vi totalt her 9*9 weights og kanter fra input layer til hidden layer. \n",
    "\n",
    "Hver rad i (input_units, hidden_units) kan man se på som weights for kantene for en input_node mot hidden_layer. Siden det er 9 kanter ut fra hver input node, så får vi 9 kolonner i hver rad. Så weights matrisen har shape (9, 9) mot hidden layer.\n",
    "\n",
    "Fra hidden layer til output_layer får vi matrise (9, 2) siden det er 9 noder i hidden layer og 2 i output layer. \n",
    "\n",
    "Jeg har valgt å bruke 2 classifications for \"left\". En for om den ansatte har forlatt bedriften, og en for om ansatte ikke har forlatt. \n",
    "(PS: Det finnes andre kanskje bedre måter å gjøre dette på når det er binær classification. Jeg fikk det bare ikke til å virke særlig bra.....)\n",
    "\n",
    "### Variabler T.F\n",
    "Weights og Biases er variabler fordi de skal optimeres/tunes for å gjøre modellen bedre. Gjennom flere kjøring gjennomgrafen innenfor samme Session, så vil disse Variable endre verdi. Verdiene blir endret basert på en kostnadsverdi som sier noe om hvor god modellen vår er til å predikere datasettet. Kommer tilbake til dette litt lenger ned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_uniform((ANTALL_FEATURES, HIDDEN_UNITS), -1, 1), dtype=tf.float32),\n",
    "    'output': tf.Variable(tf.random_normal( (HIDDEN_UNITS, OUTPUT_UNITS), -1, 1), dtype=tf.float32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([HIDDEN_UNITS]), dtype=tf.float32) ,\n",
    "    'output': tf.Variable(tf.random_normal([OUTPUT_UNITS]), dtype=tf.float32)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppbygging av modell i Tensorflow graf\n",
    "Så nå kan vi endelig begynne å bygge opp kalkulasjonene, noe som i Tensorflow betyr å bygge opp grafen med Operations.\n",
    "\n",
    "Første vi ønsker å gjøre å bygge opp graf for kalkulasjonen vi trenger å gjøre for å regne ut Activation noder i hidden layer. Dette gjøres ved å multiplisere input verdiene X, med tilhørende weights på kanter inn mot Activation node. Når X og Weights blir multiplisert, så blir hver observasjon/ansatt(rad) i X, multiplisert med alle vekter i Weights matrisen.\n",
    "For å gjøre dette i TF så bruker vi operasjonen \"tf.matmul()\" som tar inn tensorene(aka n-arrays) som skal multipliseres.\n",
    "\n",
    "(Activation node = navnet på en node i Hidden layers)\n",
    "\n",
    "Resultat fra multiplikasjonen ligger i \"hidden_multi\". Det er en ny Tensor(matrise) med shape(antall_ansatte_data, antall_output) (uvisst, 2). Dette er fordi \"x\" har shape (antall_ansatte, antall_features) og \"weights\" har shape (antall_features, antall_hidden_untis), og dette til sammen gir en Tensor med shape (antall_ansatte_data, antall_hidden_units). \n",
    "Denne utregningen har gitt oss vektet sum for alle Activation nodes(hidden layer noder) i første hidden layer.\n",
    "\n",
    "PS --> shape = (rader, kolonner).\n",
    "\n",
    "Vi legger til slutt på bias med \"tf.add\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_multi = tf.matmul(x_placeh, weights['hidden'])\n",
    "\n",
    "hidden_layer = tf.add(hidden_multi, biases['hidden'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now logits is a matrix with num_images rows and num_classes columns, where the element of the $i$'th row and $j$'th column is an estimate of how likely the $i$'th input image is to be of the $j$'th class.\n",
    "However, these estimates are a bit rough and difficult to interpret because the numbers may be very small or large, so we want to normalize them so that each row of the logits matrix sums to one, and each element is limited between zero and one. This is calculated using the so-called relu function and the result is stored in hidden_layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_layer_h = tf.nn.relu(hidden_layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_layer = tf.matmul(hidden_layer_h, weights['output']) + biases['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I output layer ligger nå 2 verdier som ikke gir så mye mening i seg selv, men de representerer sannsynligheten for at en observasjon er \"left=1\" og \"left=0\". For å få tallene på en litt mer normal sannsynlighetsformat bruker vi Softmax. Denne presser sammen tallen slik at tallene fra begge(alle) outputtene summeres opp til totalt 1. Tallene kan nå tolkes som sannsynligheter. \n",
    "\n",
    "For å avgjøre hvilke av de to klassen som blir predikert, tar vi bare den med høyest sannsynlighet av de to. \n",
    "Dette gjøres ved bruk av \"argmax\" som tar det høyeste verdien over en akse i matrisen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finner ekte predikert klasse i 1 og 0 type. Ikke klasse type. Går på kolonner\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost\n",
    "\n",
    "For å kunne optimalisere modellen vår så trenger vi en måte å måle kostnad for Nettverket på et gitt tidspunkt. Med andre ord, hvor mye bommer vår modell med predikeringen på et gitt tidspunkt. Man sammenligner da predikert verdi med faktisk observert verdi. \n",
    "Dette blir representerte ved \"cross_e_cost\" som er et positivt tall. Ikke Tensor.\n",
    "\n",
    "Cross-Entropy er en function som måler hvor god modellen vår er. Den gir alltid et positivt resultat og hvis modellens prediksjoner er helt lik faktiske observasjon, så vil cross-entropy outputte 0. Målet for optimalisering er derfor å minimalisere outputten fra cross_entropy ved å tune Variablene i grafen. Her blir det \"Weights\" og \"Biases\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_e_cost = tf.nn.softmax_cross_entropy_with_logits(logits=output_layer, labels=y_placeh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her blir bare gjennomsnittlig kostnad for alle predikeringene lagt sammen til en kostnads-scalar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_e_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Optimering\n",
    "Så til optimering. Her må vi velge en algoritme vi ønsker å bruke for å optimere modellen vår. Jeg kommer bare til å bruke vanilla Gradient Descent da den er den mest kjente utgaven av Gradient Descent, men Tensorflow har mange forskjellig optimeringsmodeller tilgjengelig som bygger på samme prinsimm som GD.\n",
    "\n",
    "Når man kaller \".minimize\" i optimizer vil Tensorflow kalkulere den partiellderiverte(Gradient) med hensyn på \"cross_e_cost\" for alle Variables som er i kalkulasjonsgrafen som bestemmer modellens kostnad. Videre bruker modellen disse deriverte til å optimalisere weights og biases i modellen for å minimere kostnaden.  \n",
    "\n",
    "Learing Rate har jeg bare valgt å sette til 0.05 . Det er ganske random. Skal man gjøre det grundig bruker man gjerne Valideringssettet av datasettet for å finne den beste læringsraten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning Rate er også valgt litt tilfeldig innfor rimlighet\n",
    "learning_rate = 0.05\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Accuracy stuff \n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls_placeh)\n",
    "\n",
    "# Regner accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialiserer noen faste variabler. \n",
    "# Epoch -> Hvor mange ganger man går igjenom datasettet for å trene\n",
    "# Batch størrelse -> Hvor mange observasjoner(Ansatte) skal vi trene på om gangen.\n",
    "\n",
    "epochs = 5\n",
    "batch_str = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Her kan vi legge til seed senere kanskje\n",
    "#[row,col]. Så [0:10,:] betyr hent rad 0 til 10 og ta med alle kolonner\n",
    "\n",
    "def lag_en_batch(batch_str, dataset_x, dataset_label, antall_batch_kjørt):\n",
    "    start = batch_str * antall_batch_kjørt\n",
    "    stop = start + batch_str\n",
    "    if stop > len(data_train):\n",
    "        stop = len(data_train)\n",
    "    batch_x = dataset_x[ start:stop, 0:ANTALL_FEATURES ]  \n",
    "    batch_label = dataset_label[start:stop]\n",
    "    return batch_x, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "feed_dict_test = {x_placeh: x_test,\n",
    "                  y_placeh: y_hot_train,\n",
    "                  y_true_cls_placeh: y_test_cls}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_accuracy():\n",
    "    # Use TensorFlow to compute the accuracy.\n",
    "    acc = sess.run(accuracy, feed_dict=feed_dict_test)\n",
    "    \n",
    "    # Print the accuracy.\n",
    "    print(\"Accuracy on test-set: {0:.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-297-eb1796c03fa6>:2: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Gir oss en Operasjon/Operation som kan initialisere alle variablene i grafen.\n",
    "init_global = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Start session\n",
    "Session er noe vi deployer vår graf til. Det vil si at vi binder Grafen til en execution context hvor grafen lever, Contexteten kan være f.eks en CPU eller GPU som støtter kjøring av Grafen.\n",
    "Det er først når vi har laget en session at vi kan begynne å kjøre alt vi har lagt til Grafen vår.\n",
    "\n",
    "Bruker Stochastic Gradient Decent slik at det tar kortere tid å optimalisere. Dette betyr at vi trener modellen på flere observasjoner i en batch i stedenfor 1 og 1 observasjon. \n",
    "\n",
    "Til slutt ser kalkulerer vi treffsikkerheten av modellen og ser på hvordan weights endte opp etter treningen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch nummer: 1  cost: 205.10649738928015\n",
      "Epoch nummer: 2  cost: 0.5500064886222451\n",
      "Epoch nummer: 3  cost: 0.548132061958313\n",
      "Epoch nummer: 4  cost: 0.5479222950288806\n",
      "Epoch nummer: 5  cost: 0.5478953522140697\n",
      "Ferdig med trening!\n",
      "\n",
      "\n",
      "Start accuracy\n",
      "Validation Accuracy: 0.7593333125114441\n",
      "\n",
      "\n",
      "Skriver ut trente verdier av vektene.\n",
      "\n",
      "Features:\n",
      "satisfaction_level, last_evaluation, number_project, average_montly_hours,time_spend_company, Work_accident, promotion_last_5year, sales, salary\n",
      "\n",
      "{'hidden': array([[ -0.02637012,   0.59817493,  -0.70099372,   0.94648504,\n",
      "          0.59067225,  -0.44117117,  -1.02326941,  -0.90137482,\n",
      "          0.72714645],\n",
      "       [ -0.53295147,   0.93141586,  -0.75553823,  -0.33216977,\n",
      "         -0.6226058 ,   0.5965662 ,  -0.34336624,   0.40418884,\n",
      "         -0.34483442],\n",
      "       [ -0.37932605,  -0.58957648,   0.66730016,   0.98086476,\n",
      "          0.51418567,   0.61389351,   0.03882217,  -0.84188592,\n",
      "          0.25873357],\n",
      "       [ -8.58134556, -10.08387661,  -4.3999157 ,  -0.26024413,\n",
      "         -0.67105484,  -0.24174047, -24.24160004, -12.6366663 ,  -8.4516964 ],\n",
      "       [ -0.22894694,  -1.10233498,   0.14122039,   0.40506482,\n",
      "         -0.97196937,   0.52756429,  -0.66157317,   0.56708908,\n",
      "          0.78163958],\n",
      "       [  0.09493704,   0.26863921,  -0.1227432 ,   0.84080315,\n",
      "         -0.92258477,   0.27571702,   0.62945163,   0.57538927,\n",
      "          0.04023002],\n",
      "       [ -0.97211355,  -0.41740781,  -0.34369269,   0.42027497,\n",
      "          0.22739339,   0.90543962,  -0.43839276,   0.27835548,\n",
      "          0.74814725],\n",
      "       [  0.15370238,  -0.09118557,   0.65039217,  -0.91635823,\n",
      "          0.70711446,  -0.36300111,   0.27751574,  -0.24297276,   0.2651335 ],\n",
      "       [ -0.68816775,   0.91190863,  -0.98774892,  -0.11906672,\n",
      "         -0.697402  ,  -0.11687446,  -0.81936264,   0.55901086,\n",
      "         -0.14246233]], dtype=float32), 'output': array([[  3.61951113,  -6.09167385],\n",
      "       [  4.24218321,  -6.4320426 ],\n",
      "       [  2.99849892,  -4.43111086],\n",
      "       [ -3.00565481,  -1.67088723],\n",
      "       [ -1.27676511,   0.30061626],\n",
      "       [ -2.69274592,  -1.34806585],\n",
      "       [-11.26648998,   7.09584713],\n",
      "       [-25.99664307,  24.59845543],\n",
      "       [-19.82226181,  20.17966843]], dtype=float32)}\n",
      "Blaa \n",
      "\n",
      "\n",
      "Tensor(\"add_6:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Først initialiserer vi Variablene våre \n",
    "    sess.run(init_global)\n",
    "    \n",
    "    # Hvor mange Epocher skal vi kjøre over datasettet\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Gjennomsnittlig kost for hver observasjon i datasettet. Finner også antall batcher vi skal kjøre\n",
    "        average_cost = 0\n",
    "        antall_batcher = int(data_train.shape[0]/batch_str)\n",
    "        \n",
    "        for i in range(antall_batcher):\n",
    "            batch_x, batch_label = lag_en_batch(batch_str, x_train, y_hot_train, i)\n",
    "\n",
    "            feed_dict_train = {x_placeh: batch_x, y_placeh: batch_label}\n",
    "            \n",
    "            _ ,current_cost = sess.run([optimizer, cost], feed_dict={x_placeh: batch_x, y_placeh: batch_label})\n",
    "            \n",
    "            average_cost += current_cost/antall_batcher\n",
    "            \n",
    "        print(\"Epoch nummer: {}  cost: {}\".format( (epoch+1), average_cost))\n",
    "    \n",
    "    print(\"Ferdig med trening!\\n\\n\") \n",
    "    \n",
    "    # find predictions on val set\n",
    "    print(\"Start accuracy\")\n",
    "    \n",
    "    # Henter kolonnenen med høyest tall i \"output_layer\" og \"y_placeh\" matrisene. Deretter sammenligner om like\n",
    "    \n",
    "    pred_temp = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y_placeh, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(pred_temp, \"float\"))\n",
    "    out = accuracy.eval({x_placeh: x_test.reshape(-1, ANTALL_FEATURES), y_placeh: y_hot_test})\n",
    "\n",
    "    print (\"Validation Accuracy: {}\\n\\n\".format(out))\n",
    "    \n",
    "    print (\"Skriver ut trente verdier av vektene.\\n\")\n",
    "    print (\"Features:\")\n",
    "    print (\"satisfaction_level, last_evaluation, number_project, average_montly_hours,\" + \n",
    "           \"time_spend_company, Work_accident, promotion_last_5year, sales, salary\\n\")\n",
    "    # Henter de nye vektene som er trent! \n",
    "    # Får 2 arrays. 1 for Input til Hidden layer, og 1 for Hidden layer til Output layer\n",
    "    vekter = sess.run(weights)\n",
    "    \n",
    "    print(vekter)\n",
    "\n",
    "    print(\"Blaa \\n\\n\")\n",
    "    #output = sess.run(output_layer)\n",
    "    print(output_layer)\n",
    "    predict = tf.argmax(output_layer, 1)\n",
    "    pred = predict.eval({x_placeh: x_test.reshape(-1, ANTALL_FEATURES)})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hr_data_testing = pd.read_csv('data/HR_comma_sep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hr_data_testing = hr_data_testing.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.89</td>\n",
       "      <td>6</td>\n",
       "      <td>264</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>4</td>\n",
       "      <td>197</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6</td>\n",
       "      <td>305</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>accounting</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>4</td>\n",
       "      <td>133</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hr</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2</td>\n",
       "      <td>282</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>marketing</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.91</td>\n",
       "      <td>6</td>\n",
       "      <td>222</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>marketing</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4</td>\n",
       "      <td>264</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>product_mng</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.94</td>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>management</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>product_mng</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.84</td>\n",
       "      <td>7</td>\n",
       "      <td>133</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RandD</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.77</td>\n",
       "      <td>5</td>\n",
       "      <td>233</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4</td>\n",
       "      <td>243</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>product_mng</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.56</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.85</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.84</td>\n",
       "      <td>6</td>\n",
       "      <td>246</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hr</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4</td>\n",
       "      <td>251</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RandD</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                 0.11             0.89               6                   264   \n",
       "1                 0.59             0.57               4                   197   \n",
       "2                 0.11             0.85               6                   305   \n",
       "3                 0.75             0.83               4                   133   \n",
       "4                 0.39             0.68               2                   282   \n",
       "5                 0.22             0.91               6                   222   \n",
       "6                 0.09             0.95               7                   256   \n",
       "7                 0.90             0.98               4                   264   \n",
       "8                 0.63             0.94               3                   172   \n",
       "9                 0.99             0.94               5                   151   \n",
       "10                0.31             0.84               7                   133   \n",
       "11                0.56             0.64               3                   260   \n",
       "12                0.94             0.77               5                   233   \n",
       "13                0.83             0.73               5                   136   \n",
       "14                0.63             0.53               4                   243   \n",
       "15                0.29             0.95               5                   117   \n",
       "16                0.40             0.56               2                   131   \n",
       "17                0.65             0.85               4                   172   \n",
       "18                0.10             0.84               6                   246   \n",
       "19                0.55             0.93               4                   251   \n",
       "\n",
       "    time_spend_company  Work_accident  left  promotion_last_5years  \\\n",
       "0                    4              0     1                      0   \n",
       "1                    2              0     0                      0   \n",
       "2                    4              0     1                      0   \n",
       "3                    4              0     0                      0   \n",
       "4                    5              0     1                      0   \n",
       "5                    8              0     0                      0   \n",
       "6                    4              0     1                      0   \n",
       "7                    6              0     1                      0   \n",
       "8                    3              0     0                      0   \n",
       "9                    3              0     0                      0   \n",
       "10                   5              0     1                      0   \n",
       "11                   3              0     0                      0   \n",
       "12                   4              0     0                      0   \n",
       "13                   3              0     0                      0   \n",
       "14                   2              0     0                      0   \n",
       "15                   4              0     0                      0   \n",
       "16                   3              0     1                      0   \n",
       "17                   3              0     0                      0   \n",
       "18                   4              0     1                      0   \n",
       "19                   4              1     0                      0   \n",
       "\n",
       "          sales  salary  \n",
       "0       support     low  \n",
       "1         sales  medium  \n",
       "2    accounting  medium  \n",
       "3            hr    high  \n",
       "4     marketing     low  \n",
       "5     technical     low  \n",
       "6     marketing  medium  \n",
       "7   product_mng  medium  \n",
       "8    management  medium  \n",
       "9   product_mng  medium  \n",
       "10    technical     low  \n",
       "11        RandD  medium  \n",
       "12    technical    high  \n",
       "13        sales     low  \n",
       "14    technical     low  \n",
       "15  product_mng     low  \n",
       "16           IT     low  \n",
       "17        sales  medium  \n",
       "18           hr  medium  \n",
       "19        RandD     low  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_data_testing.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hr_data_testing['sales'].replace(['sales', 'accounting', 'hr', 'technical', 'support', 'management',\n",
    "        'IT', 'product_mng', 'marketing', 'RandD'], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], inplace = True)\n",
    "\n",
    "hr_data_testing['salary'].replace(['low', 'medium', 'high'], [0, 1, 2], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = hr_data_testing.iloc[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
